# Configuration for LLM Decision Evaluation System
# This config controls which models are evaluated, which cases to use, and execution parameters

# Case selection configuration
case_selection:
  # mode: Controls which cases to evaluate
  #   - "approved": Use only cases with status="approved" (default)
  #   - "all": Use all cases regardless of status
  #   - "explicit": Use specific case IDs listed in case_ids
  mode: explicit
  
  # case_ids: List of specific case IDs (only used when mode is "explicit")
  # Example: ["case_001", "case_002", "case_003"]
  case_ids: 
    - "8c1c8374-ab03-4bf7-a4ef-b5b225422685"
    - "eee77bbb-0416-4c4c-b1d5-26165571eb9b"
    - "b0a439fe-8ab8-450b-9e72-dbce2726a37e"
    - "10199c7b-b781-474f-a9e3-751bdfd9288a"
    - "88292af4-c4be-4a91-81c6-3f7c7fd4b574"
    - "3e0c9fbc-7c0c-464a-881a-1cad43601591"
    - "d9b904c3-80de-486b-9b63-0bdb58f733a3"
    - "e0c6ee6e-c005-4b00-9ea9-478fceda1e19"
    - "feec8675-056c-445c-a654-28dc91e1c511"
    - "7129cbd9-42d9-42da-86e6-7132d1f0369c"
    - "ec137441-228d-4234-b595-32e6772f3b3f"
    - "1b570980-2a9a-41a3-87a8-d3a7439f5ed5"
    - "71073932-0517-418a-9e0d-40423a4f1755"
    - "065d7abf-3671-43a2-8375-79fb6e87ed78"
    - "7b8a4a5e-4119-48e2-ab3d-72c2d0684718"
    - "ba711ccb-a7ab-493f-84c5-39f735feb806"
    - "731f6c10-7da1-4140-97ea-dbc609c428d6"
    - "c66799aa-41ba-497c-824c-1e2e9b66b60c"
    - "82d191f9-5472-4905-8c3d-de170b9dc85b"
    - "2529588f-f37c-4af4-86d8-1d5eb99466f5"
    - "7f52898a-aca8-476f-ad50-4b9851fca821"
    - "ca48bd78-c209-4c82-80c4-37438e90e68a"
    - "9b7e0b45-ee7a-4de7-8961-eab9091bc99e"
    - "b3f8664c-ddaf-4d9a-81b8-6bb06c11e9c6"
    - "beef02d0-02a4-45a5-b020-906846fe8bd8"
    - "0c790bb1-dd0d-4724-8502-e8613968dd04"
    - "2f51d70e-facc-45fa-a520-ec3d2fc17b44"
    - "0dd9fa12-e3fa-4243-8a4f-2b34052734dc"
    - "282a2bc8-6ccb-4f34-a265-ff9540f7d2dc"
    - "7bd46c3e-76f0-4cdc-bf02-016e944c77cd"
    - "24bf2c00-5b29-4701-9930-39798cd6c75b"
    - "dee07a00-bf07-49ab-b334-35158bab1b9d"
    - "a8d7dbba-43b5-48ab-9855-e65266ae2f23"
    - "f35da35f-257c-4b85-9b8c-5ebcd8a464d4"
    - "4aab5d3c-9a4e-40c2-b074-b4d9be1c4116"
    - "bf65986f-b06d-43eb-b7a9-e9febd1ca6cd"
    - "f184f7c6-1a27-4ba7-a02a-74f3eeeb558b"
    - "6519444e-8565-4d94-882b-19d5cd4f08a7"
    - "1f92a8ed-c2ad-4856-b7c4-272f9a68d2a6"
    - "a00e045a-a1ad-4635-bc4d-860f71ca01e0"
    - "b01b61b0-5f1e-4030-acd3-dfefa7136ca4"
    - "4b731f8c-84a3-4191-9eb2-28aae57e1bc9"
    - "665d81cb-3074-4457-8af0-bb437f386b7b"
    - "9cf163fb-fb6c-4f2d-949f-c34d8d430d52"
    - "b94607ef-e355-4a64-b564-2a558c0eea71"
    - "0b5a2bcb-0946-461a-8ba1-8f29213f01c5"
    - "54cefefd-cafa-410f-8ccc-eee8b9bf4ab0"
    - "ecdf28d6-3d88-4916-9b3c-67ef077fafc5"
    - "a4bf234a-6888-4825-8fb4-40e6afe55489"
    - "ae2ddcf4-a8c7-4e49-9a40-81a56cfeb2fc"
    - "5ce660f0-67cd-48b5-8316-e147b578a7c9"

# Models to evaluate
# List of model identifiers in the format "provider/model-name"
models:
  # - openai/gpt-oss-120b
  - openai/gpt-5.2
  # - qwen/qwen3-235b-a22b-2507
  # - qwen/qwen3-max
  # - anthropic/claude-sonnet-4.5
  # - anthropic/claude-opus-4.5    
  # - anthropic/claude-haiku-4.5
  # - deepseek/deepseek-v3.2
  # - deepseek/deepseek-chat
  # - google/gemini-3-pro-preview
  # - google/gemini-2.5-flash
  # - meta-llama/llama-3.3-70b-instruct
  # - meta-llama/llama-4-maverick  
  # - mistralai/mistral-nemo
  # - mistralai/mistral-large-2512
  # - moonshotai/kimi-k2-thinking
  # - x-ai/grok-4
  # - minimax/minimax-m2
  # - z-ai/glm-4.6
  # - nvidia/llama-3.1-nemotron-ultra-253b-v1
  # - nvidia/nemotron-nano-12b-v2-vl
  # - amazon/nova-premier-v1
  # - baidu/ernie-4.5-vl-424b-a47b
  # - deepcogito/cogito-v2.1-671b
  # - cohere/command-a
  # - perplexity/sonar-pro

# Execution settings
execution:
  runs_per_model: 10  # Number of independent runs per model per case
  temperature: 1.0    # Sampling temperature for target models
  parser_model: openai/gpt-4o-mini  # Model used to parse LLM responses

# Retry configuration
retry:
  max_api_retries: 3        # Maximum retries for API calls to target models
  max_parse_retries: 2      # Maximum retries for parsing responses
  backoff_base: 2.0         # Exponential backoff base (seconds)

# Output configuration
output:
  dir: data/llm_decisions  # Directory to store evaluation results
